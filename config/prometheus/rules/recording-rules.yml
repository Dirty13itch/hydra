# Prometheus Recording Rules for Hydra Cluster
#
# Recording rules precompute frequently-used expressions for faster
# dashboard loading and more efficient alerting.
#
# Deploy to: /mnt/user/appdata/prometheus/rules/recording-rules.yml
# Generated: December 14, 2025

groups:
  # ===========================================
  # GPU METRICS AGGREGATIONS
  # ===========================================
  - name: gpu_recording_rules
    interval: 30s
    rules:
      # Total VRAM used across all GPUs
      - record: hydra:gpu:vram_used_total_gb
        expr: sum(nvidia_gpu_memory_used_bytes or DCGM_FI_DEV_FB_USED) / 1024 / 1024 / 1024

      # Total VRAM capacity across all GPUs
      - record: hydra:gpu:vram_total_gb
        expr: sum(nvidia_gpu_memory_total_bytes or DCGM_FI_DEV_FB_TOTAL) / 1024 / 1024 / 1024

      # VRAM usage percentage cluster-wide
      - record: hydra:gpu:vram_used_pct
        expr: |
          (sum(nvidia_gpu_memory_used_bytes or DCGM_FI_DEV_FB_USED) /
           sum(nvidia_gpu_memory_total_bytes or DCGM_FI_DEV_FB_TOTAL)) * 100

      # Average GPU temperature across all GPUs (Celsius)
      - record: hydra:gpu:temp_avg_c
        expr: avg(nvidia_gpu_temp_c or DCGM_FI_DEV_GPU_TEMP)

      # Max GPU temperature (hottest GPU)
      - record: hydra:gpu:temp_max_c
        expr: max(nvidia_gpu_temp_c or DCGM_FI_DEV_GPU_TEMP)

      # Total GPU power draw (Watts)
      - record: hydra:gpu:power_total_w
        expr: sum(nvidia_gpu_power_draw_watts or DCGM_FI_DEV_POWER_USAGE)

      # Average GPU utilization
      - record: hydra:gpu:utilization_avg_pct
        expr: avg(nvidia_gpu_utilization_pct or DCGM_FI_DEV_GPU_UTIL)

      # Per-node VRAM usage
      - record: hydra:gpu:vram_used_by_node
        expr: |
          sum by (instance) (nvidia_gpu_memory_used_bytes or DCGM_FI_DEV_FB_USED) / 1024 / 1024 / 1024

  # ===========================================
  # NODE METRICS AGGREGATIONS
  # ===========================================
  - name: node_recording_rules
    interval: 30s
    rules:
      # Average CPU usage across cluster
      - record: hydra:cluster:cpu_avg_pct
        expr: |
          100 - (avg(rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

      # Memory usage percentage by node
      - record: hydra:node:memory_used_pct
        expr: |
          (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100

      # Average memory usage across cluster
      - record: hydra:cluster:memory_avg_pct
        expr: |
          avg((1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100)

      # Disk usage percentage (root filesystem)
      - record: hydra:node:disk_used_pct
        expr: |
          (1 - (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"})) * 100

      # Network bytes received per second by node
      - record: hydra:node:network_rx_bytes_rate
        expr: rate(node_network_receive_bytes_total{device!~"lo|docker.*|br-.*|veth.*"}[5m])

      # Network bytes transmitted per second by node
      - record: hydra:node:network_tx_bytes_rate
        expr: rate(node_network_transmit_bytes_total{device!~"lo|docker.*|br-.*|veth.*"}[5m])

  # ===========================================
  # CONTAINER METRICS
  # ===========================================
  - name: container_recording_rules
    interval: 30s
    rules:
      # Total running containers
      - record: hydra:containers:running_total
        expr: count(container_last_seen{name!=""})

      # Container CPU usage by name (1m average)
      - record: hydra:container:cpu_usage_pct
        expr: |
          sum by (name) (rate(container_cpu_usage_seconds_total[1m])) * 100

      # Container memory usage by name (bytes)
      - record: hydra:container:memory_usage_bytes
        expr: sum by (name) (container_memory_usage_bytes)

      # Container restart count (last hour)
      - record: hydra:container:restarts_1h
        expr: |
          increase(container_start_time_seconds[1h]) > 0

  # ===========================================
  # SERVICE HEALTH
  # ===========================================
  - name: service_recording_rules
    interval: 60s
    rules:
      # Prometheus target up percentage
      - record: hydra:prometheus:targets_up_pct
        expr: (sum(up) / count(up)) * 100

      # HTTP request latency by service (p50)
      - record: hydra:http:latency_p50_ms
        expr: |
          histogram_quantile(0.50, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)) * 1000

      # HTTP request latency by service (p95)
      - record: hydra:http:latency_p95_ms
        expr: |
          histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)) * 1000

      # HTTP request latency by service (p99)
      - record: hydra:http:latency_p99_ms
        expr: |
          histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)) * 1000

  # ===========================================
  # INFERENCE METRICS
  # ===========================================
  - name: inference_recording_rules
    interval: 30s
    rules:
      # TabbyAPI requests per second
      - record: hydra:inference:requests_per_sec
        expr: rate(tabby_requests_total[5m])

      # TabbyAPI average latency (if metrics available)
      - record: hydra:inference:latency_avg_ms
        expr: |
          rate(tabby_request_duration_seconds_sum[5m]) /
          rate(tabby_request_duration_seconds_count[5m]) * 1000

      # Tokens generated per second (if metrics available)
      - record: hydra:inference:tokens_per_sec
        expr: rate(tabby_tokens_generated_total[5m])

  # ===========================================
  # STORAGE METRICS (UNRAID)
  # ===========================================
  - name: storage_recording_rules
    interval: 60s
    rules:
      # Total storage used (Unraid array)
      - record: hydra:storage:used_tb
        expr: |
          sum(node_filesystem_size_bytes{mountpoint=~"/mnt/disk.*|/mnt/user.*"} -
              node_filesystem_avail_bytes{mountpoint=~"/mnt/disk.*|/mnt/user.*"}) / 1024 / 1024 / 1024 / 1024

      # Total storage capacity
      - record: hydra:storage:total_tb
        expr: |
          sum(node_filesystem_size_bytes{mountpoint=~"/mnt/disk.*|/mnt/user.*"}) / 1024 / 1024 / 1024 / 1024

      # Storage usage percentage
      - record: hydra:storage:used_pct
        expr: |
          (1 - (sum(node_filesystem_avail_bytes{mountpoint=~"/mnt/disk.*|/mnt/user.*"}) /
                sum(node_filesystem_size_bytes{mountpoint=~"/mnt/disk.*|/mnt/user.*"}))) * 100

  # ===========================================
  # DATABASE METRICS
  # ===========================================
  - name: database_recording_rules
    interval: 60s
    rules:
      # PostgreSQL active connections
      - record: hydra:postgres:active_connections
        expr: pg_stat_activity_count{state="active"}

      # PostgreSQL database sizes
      - record: hydra:postgres:database_size_mb
        expr: pg_database_size_bytes / 1024 / 1024

      # Redis memory usage
      - record: hydra:redis:memory_used_mb
        expr: redis_memory_used_bytes / 1024 / 1024

      # Redis connected clients
      - record: hydra:redis:connected_clients
        expr: redis_connected_clients

      # Qdrant collection vector counts
      - record: hydra:qdrant:vectors_total
        expr: sum(qdrant_collection_points_count)

  # ===========================================
  # DASHBOARD OPTIMIZATIONS
  # ===========================================
  - name: dashboard_recording_rules
    interval: 60s
    rules:
      # Cluster health score (0-100)
      # Based on: targets up, GPU temps, memory, disk
      - record: hydra:cluster:health_score
        expr: |
          clamp_max(
            ((sum(up) / count(up)) * 25) +
            (clamp_max(100 - avg(nvidia_gpu_temp_c), 100) / 100 * 25) +
            (clamp_max(100 - avg((1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100), 100) / 100 * 25) +
            (clamp_max(100 - avg((1 - (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"})) * 100), 100) / 100 * 25),
            100
          )

      # 5-minute average metrics for sparklines
      - record: hydra:dashboard:cpu_5m_avg
        expr: avg_over_time(hydra:cluster:cpu_avg_pct[5m])

      - record: hydra:dashboard:memory_5m_avg
        expr: avg_over_time(hydra:cluster:memory_avg_pct[5m])

      - record: hydra:dashboard:gpu_temp_5m_avg
        expr: avg_over_time(hydra:gpu:temp_avg_c[5m])

      - record: hydra:dashboard:vram_5m_avg
        expr: avg_over_time(hydra:gpu:vram_used_pct[5m])

  # ===========================================
  # PREDICTIVE MAINTENANCE RULES
  # ===========================================
  - name: predictive_maintenance
    interval: 60s
    rules:
      # -----------------------------------------
      # DISK PREDICTIONS
      # -----------------------------------------
      # Predict disk usage 24 hours from now (percent)
      - record: disk:predicted_usage_24h:percent
        expr: |
          100 * (1 - (
            predict_linear(node_filesystem_avail_bytes{fstype!~"tmpfs|overlay"}[6h], 86400) /
            node_filesystem_size_bytes
          ))

      # Hours until disk is full (based on current fill rate)
      - record: disk:time_to_full:hours
        expr: |
          (node_filesystem_avail_bytes{fstype!~"tmpfs|overlay"} /
           (-deriv(node_filesystem_avail_bytes{fstype!~"tmpfs|overlay"}[6h]) + 1)) / 3600

      # -----------------------------------------
      # GPU VRAM PREDICTIONS
      # -----------------------------------------
      # Predict VRAM usage 1 hour from now (percent) - nvidia-smi format
      - record: gpu:predicted_vram_1h:percent
        expr: |
          100 * (
            predict_linear(nvidia_gpu_memory_used_bytes[1h], 3600) /
            nvidia_gpu_memory_total_bytes
          )

      # Predict VRAM usage 1 hour from now (percent) - DCGM format
      - record: gpu:predicted_vram_1h_dcgm:percent
        expr: |
          100 * (
            predict_linear(DCGM_FI_DEV_FB_USED[1h], 3600) /
            DCGM_FI_DEV_FB_TOTAL
          )

      # -----------------------------------------
      # GPU THERMAL PREDICTIONS
      # -----------------------------------------
      # Predict GPU temperature 10 minutes from now (Celsius) - nvidia-smi
      - record: gpu:predicted_temp_10m:celsius
        expr: predict_linear(nvidia_gpu_temp_c[30m], 600)

      # Predict GPU temperature 10 minutes from now (Celsius) - DCGM
      - record: gpu:predicted_temp_10m_dcgm:celsius
        expr: predict_linear(DCGM_FI_DEV_GPU_TEMP[30m], 600)

      # Temperature change rate per minute - nvidia-smi
      - record: gpu:temp_change_rate:per_minute
        expr: deriv(nvidia_gpu_temp_c[10m]) * 60

      # Temperature change rate per minute - DCGM
      - record: gpu:temp_change_rate_dcgm:per_minute
        expr: deriv(DCGM_FI_DEV_GPU_TEMP[10m]) * 60

      # -----------------------------------------
      # SYSTEM MEMORY PREDICTIONS
      # -----------------------------------------
      # Predict memory usage 1 hour from now (percent)
      - record: node:predicted_memory_usage_1h:percent
        expr: |
          100 * (1 - (
            predict_linear(node_memory_MemAvailable_bytes[1h], 3600) /
            node_memory_MemTotal_bytes
          ))

      # -----------------------------------------
      # CLUSTER HEALTH SCORE
      # -----------------------------------------
      # Overall cluster health score (0-100)
      - record: cluster:health_score:percent
        expr: |
          clamp_max(
            clamp_min(
              ((sum(up) / count(up)) * 40) +
              (clamp_max(100 - max(nvidia_gpu_temp_c), 60) / 100 * 30) +
              (clamp_max(100 - max((1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100), 100) / 100 * 15) +
              (clamp_max(100 - max((1 - (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"})) * 100), 100) / 100 * 15),
              0
            ),
            100
          )

  # ===========================================
  # CHARACTER GENERATION METRICS (Phase 12)
  # ===========================================
  - name: character_generation_rules
    interval: 60s
    rules:
      # Portrait generation request rate (per minute)
      - record: hydra:character:generation_rate_1m
        expr: rate(hydra_character_portraits_generated_total[1m]) * 60

      # Portrait generation success rate (percentage)
      - record: hydra:character:success_rate_pct
        expr: |
          (sum(hydra_character_portraits_success_total) /
           sum(hydra_character_portraits_generated_total)) * 100

      # Average quality score across all generated assets
      - record: hydra:character:avg_quality_score
        expr: avg(hydra_asset_quality_score)

      # Assets pending review count
      - record: hydra:character:pending_review_count
        expr: sum(hydra_asset_quality_pending_review)

      # Auto-approved assets rate (percentage)
      - record: hydra:character:auto_approve_rate_pct
        expr: |
          (sum(hydra_asset_quality_auto_approved_total) /
           sum(hydra_asset_quality_evaluated_total)) * 100

      # Auto-rejected assets rate (percentage)
      - record: hydra:character:auto_reject_rate_pct
        expr: |
          (sum(hydra_asset_quality_auto_rejected_total) /
           sum(hydra_asset_quality_evaluated_total)) * 100

      # Average generation latency (seconds)
      - record: hydra:character:generation_latency_avg_sec
        expr: |
          rate(hydra_character_generation_duration_seconds_sum[5m]) /
          rate(hydra_character_generation_duration_seconds_count[5m])

      # Quality score by dimension (for breakdown charts)
      - record: hydra:character:quality_by_dimension
        expr: avg by (dimension) (hydra_asset_quality_dimension_score)

      # Characters with complete portrait sets (percentage)
      - record: hydra:character:portrait_coverage_pct
        expr: |
          (sum(hydra_character_portraits_complete) /
           sum(hydra_character_total)) * 100

      # ComfyUI workflow execution time (seconds)
      - record: hydra:comfyui:workflow_execution_avg_sec
        expr: |
          rate(comfyui_workflow_execution_seconds_sum[5m]) /
          rate(comfyui_workflow_execution_seconds_count[5m])

      # ComfyUI queue depth
      - record: hydra:comfyui:queue_depth
        expr: comfyui_queue_pending_count

      # ControlNet strength effectiveness (correlation with quality)
      - record: hydra:controlnet:avg_strength
        expr: avg(hydra_controlnet_strength_used)

  # ===========================================
  # EMPIRE OF BROKEN QUEENS SPECIFIC METRICS
  # ===========================================
  - name: empire_character_rules
    interval: 300s
    rules:
      # Total queens defined
      - record: empire:queens:total_count
        expr: hydra_empire_queens_total

      # Queens with reference images
      - record: empire:queens:with_reference_count
        expr: sum(hydra_empire_queen_has_reference)

      # Reference coverage percentage
      - record: empire:queens:reference_coverage_pct
        expr: |
          (sum(hydra_empire_queen_has_reference) /
           hydra_empire_queens_total) * 100

      # Average emotion variants per queen
      - record: empire:queens:avg_emotion_variants
        expr: avg(hydra_empire_queen_emotion_count)

      # Total portraits generated for Empire
      - record: empire:portraits:total_generated
        expr: sum(hydra_empire_portraits_generated_total)

      # Portrait consistency score (face similarity across emotions)
      - record: empire:portraits:consistency_score_avg
        expr: avg(hydra_empire_portrait_consistency_score)
