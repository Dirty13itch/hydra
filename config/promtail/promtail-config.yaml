# Promtail Configuration for Hydra Cluster
# Collects logs from Docker containers and system logs
#
# Deploy to: /mnt/user/appdata/promtail/promtail-config.yaml
# This config is for hydra-storage (Unraid with Docker)

server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push
    tenant_id: hydra
    batchwait: 1s
    batchsize: 1048576
    timeout: 10s

scrape_configs:
  # Docker container logs
  - job_name: docker
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
    relabel_configs:
      # Add container name as label
      - source_labels: ['__meta_docker_container_name']
        regex: '/(.+)'
        target_label: container
      # Add container ID
      - source_labels: ['__meta_docker_container_id']
        target_label: container_id
      # Add image name
      - source_labels: ['__meta_docker_container_image']
        target_label: image
      # Extract service name from container name (strip hydra- prefix)
      - source_labels: ['__meta_docker_container_name']
        regex: '/hydra-(.+)'
        target_label: service
      # Add node label
      - target_label: node
        replacement: hydra-storage
      # Add stack label from docker-compose project
      - source_labels: ['__meta_docker_container_label_com_docker_compose_project']
        target_label: stack
    pipeline_stages:
      # Parse JSON logs
      - json:
          expressions:
            level: level
            msg: msg
            message: message
            timestamp: timestamp
            time: time
      # Use extracted level
      - labels:
          level:
      # Fallback for non-JSON logs
      - regex:
          expression: '(?P<level>INFO|WARN|ERROR|DEBUG|CRITICAL)'
      - labels:
          level:

  # System logs (journald on NixOS nodes via syslog)
  - job_name: syslog
    syslog:
      listen_address: 0.0.0.0:1514
      idle_timeout: 60s
      label_structured_data: true
      labels:
        job: syslog
    relabel_configs:
      - source_labels: ['__syslog_message_hostname']
        target_label: node
      - source_labels: ['__syslog_message_app_name']
        target_label: service
      - source_labels: ['__syslog_message_severity']
        target_label: level

  # TabbyAPI logs (if running via systemd, forwarded via syslog)
  - job_name: tabbyapi
    static_configs:
      - targets:
          - localhost
        labels:
          job: tabbyapi
          node: hydra-ai
          __path__: /var/log/tabbyapi/*.log
    pipeline_stages:
      - regex:
          expression: '(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) \| (?P<level>\w+) +\| (?P<message>.*)'
      - labels:
          level:
      - timestamp:
          source: timestamp
          format: '2006-01-02 15:04:05'

  # Inference request logs (structured)
  - job_name: inference
    static_configs:
      - targets:
          - localhost
        labels:
          job: inference
          __path__: /var/log/hydra/inference.log
    pipeline_stages:
      - json:
          expressions:
            model: model
            tokens: total_tokens
            latency_ms: latency_ms
            status: status
      - labels:
          model:
          status:
      - metrics:
          inference_tokens_total:
            type: Counter
            description: Total tokens generated
            source: tokens
            config:
              action: add
          inference_latency_milliseconds:
            type: Histogram
            description: Inference latency
            source: latency_ms
            config:
              buckets: [100, 250, 500, 1000, 2500, 5000, 10000]

# Filter out noisy logs
scrape_configs_filter:
  - job_name: docker
    pipeline_stages:
      # Drop health check spam
      - match:
          selector: '{container=~".+"}'
          stages:
            - regex:
                expression: '(health|healthz|ping|ready|live)'
            - drop:
                expression: '.*'
                drop_counter_reason: health_check
      # Drop debug logs in production
      - match:
          selector: '{level="DEBUG"}'
          stages:
            - drop:
                expression: '.*'
                drop_counter_reason: debug_logs
