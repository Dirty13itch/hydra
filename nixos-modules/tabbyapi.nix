{ config, lib, pkgs, ... }:

with lib;

let
  cfg = config.services.tabbyapi;

  # Generate TabbyAPI config.yml from Nix options
  configFile = pkgs.writeText "tabbyapi-config.yml" ''
    # TabbyAPI Configuration
    # Generated by NixOS module

    network:
      host: "${cfg.host}"
      port: ${toString cfg.port}
      disable_auth: ${boolToString cfg.disableAuth}
      ${optionalString (cfg.apiKey != null) "api_key: ${cfg.apiKey}"}
      ${optionalString (cfg.adminKey != null) "admin_key: ${cfg.adminKey}"}

    model:
      model_dir: "${cfg.modelDir}"
      ${optionalString (cfg.defaultModel != null) "model_name: ${cfg.defaultModel}"}
      max_seq_len: ${toString cfg.maxSeqLen}
      ${optionalString cfg.tensorParallel "tensor_parallel: true"}
      ${optionalString (cfg.gpuSplitAuto) "gpu_split_auto: true"}
      ${optionalString (cfg.gpuSplit != null) "gpu_split: [${concatMapStringsSep ", " toString cfg.gpuSplit}]"}
      cache_mode: "${cfg.cacheMode}"
      ${optionalString (cfg.cacheSize != null) "cache_size: ${toString cfg.cacheSize}"}

    embeddings:
      ${optionalString (cfg.embeddingsDevice != null) "embeddings_device: ${cfg.embeddingsDevice}"}

    sampling:
      override_preset: ${optionalString (cfg.samplingPreset != null) cfg.samplingPreset}

    logging:
      log_prompt: ${boolToString cfg.logPrompt}
      log_generation_params: ${boolToString cfg.logGenerationParams}

    developer:
      unsafe_launch: ${boolToString cfg.unsafeLaunch}
      disable_request_streaming: false
      cuda_malloc_backend: ${boolToString cfg.cudaMallocBackend}
  '';
in
{
  options.services.tabbyapi = {
    enable = mkEnableOption "TabbyAPI - ExLlamaV2 inference server";

    package = mkOption {
      type = types.package;
      default = pkgs.callPackage ./tabbyapi-package.nix { };
      description = "TabbyAPI package to use";
    };

    user = mkOption {
      type = types.str;
      default = "tabbyapi";
      description = "User account under which TabbyAPI runs";
    };

    group = mkOption {
      type = types.str;
      default = "tabbyapi";
      description = "Group under which TabbyAPI runs";
    };

    # Network settings
    host = mkOption {
      type = types.str;
      default = "0.0.0.0";
      description = "Host address to bind to";
    };

    port = mkOption {
      type = types.port;
      default = 5000;
      description = "Port to listen on";
    };

    disableAuth = mkOption {
      type = types.bool;
      default = true;
      description = "Disable API authentication (internal network only)";
    };

    apiKey = mkOption {
      type = types.nullOr types.str;
      default = null;
      description = "API key for authentication (if auth enabled)";
    };

    adminKey = mkOption {
      type = types.nullOr types.str;
      default = null;
      description = "Admin key for model management endpoints";
    };

    # Model settings
    modelDir = mkOption {
      type = types.path;
      default = "/mnt/models/exl2";
      description = "Directory containing EXL2 models";
    };

    defaultModel = mkOption {
      type = types.nullOr types.str;
      default = null;
      example = "Llama-3.1-70B-Instruct-exl2-4.0bpw";
      description = "Model to load on startup (null for no auto-load)";
    };

    maxSeqLen = mkOption {
      type = types.int;
      default = 8192;
      description = "Maximum sequence length (context window)";
    };

    # GPU settings
    tensorParallel = mkOption {
      type = types.bool;
      default = false;
      description = "Enable tensor parallelism across GPUs";
    };

    gpuSplitAuto = mkOption {
      type = types.bool;
      default = true;
      description = "Automatically split model across available GPUs";
    };

    gpuSplit = mkOption {
      type = types.nullOr (types.listOf types.float);
      default = null;
      example = [ 32 24 ];
      description = "Manual GPU memory allocation in GB per GPU";
    };

    # Cache settings
    cacheMode = mkOption {
      type = types.enum [ "FP16" "Q8" "Q6" "Q4" ];
      default = "Q8";
      description = "KV cache quantization mode";
    };

    cacheSize = mkOption {
      type = types.nullOr types.int;
      default = null;
      description = "Override cache size in tokens";
    };

    # Embeddings
    embeddingsDevice = mkOption {
      type = types.nullOr types.str;
      default = null;
      example = "cpu";
      description = "Device for embeddings (null for same as model)";
    };

    # Sampling
    samplingPreset = mkOption {
      type = types.nullOr types.str;
      default = null;
      example = "creative";
      description = "Default sampling preset to use";
    };

    # Logging
    logPrompt = mkOption {
      type = types.bool;
      default = false;
      description = "Log prompts (warning: may contain sensitive data)";
    };

    logGenerationParams = mkOption {
      type = types.bool;
      default = true;
      description = "Log generation parameters";
    };

    # Developer options
    unsafeLaunch = mkOption {
      type = types.bool;
      default = false;
      description = "Skip environment checks on startup";
    };

    cudaMallocBackend = mkOption {
      type = types.bool;
      default = true;
      description = "Use CUDA malloc backend for better memory management";
    };

    # Power management
    gpuPowerLimit = mkOption {
      type = types.nullOr types.int;
      default = null;
      example = 450;
      description = "GPU power limit in watts (applied before starting)";
    };

    # Environment
    extraEnvironment = mkOption {
      type = types.attrsOf types.str;
      default = { };
      example = { CUDA_VISIBLE_DEVICES = "0,1"; };
      description = "Extra environment variables for TabbyAPI";
    };
  };

  config = mkIf cfg.enable {
    # Create user and group
    users.users.${cfg.user} = {
      isSystemUser = true;
      group = cfg.group;
      extraGroups = [ "video" "render" ];
      description = "TabbyAPI service user";
    };

    users.groups.${cfg.group} = { };

    # Systemd service
    systemd.services.tabbyapi = {
      description = "TabbyAPI - ExLlamaV2 Inference Server";
      wantedBy = [ "multi-user.target" ];
      after = [ "network.target" "nvidia-persistenced.service" ];
      requires = [ "nvidia-persistenced.service" ];

      environment = {
        HOME = "/var/lib/tabbyapi";
        CUDA_VISIBLE_DEVICES = "0,1";
        PYTORCH_CUDA_ALLOC_CONF = "expandable_segments:True";
      } // cfg.extraEnvironment;

      preStart = ''
        # Apply GPU power limit if configured
        ${optionalString (cfg.gpuPowerLimit != null) ''
          echo "Setting GPU power limit to ${toString cfg.gpuPowerLimit}W"
          ${pkgs.linuxPackages.nvidia_x11.bin}/bin/nvidia-smi -pl ${toString cfg.gpuPowerLimit} || true
        ''}

        # Ensure model directory is accessible
        if [ ! -d "${cfg.modelDir}" ]; then
          echo "Warning: Model directory ${cfg.modelDir} not found"
        fi
      '';

      serviceConfig = {
        Type = "simple";
        User = cfg.user;
        Group = cfg.group;
        WorkingDirectory = "/var/lib/tabbyapi";
        StateDirectory = "tabbyapi";
        RuntimeDirectory = "tabbyapi";

        ExecStart = "${cfg.package}/bin/tabbyapi --config ${configFile}";
        Restart = "on-failure";
        RestartSec = 10;

        # Security hardening
        NoNewPrivileges = true;
        PrivateTmp = true;
        ProtectSystem = "strict";
        ProtectHome = true;
        ReadOnlyPaths = [ "/" ];
        ReadWritePaths = [
          "/var/lib/tabbyapi"
          "/var/run/tabbyapi"
          cfg.modelDir
        ];

        # GPU access
        SupplementaryGroups = [ "video" "render" ];
        DeviceAllow = [
          "/dev/nvidia0 rw"
          "/dev/nvidia1 rw"
          "/dev/nvidiactl rw"
          "/dev/nvidia-uvm rw"
          "/dev/nvidia-uvm-tools rw"
        ];

        # Resource limits
        LimitNOFILE = 65536;
        LimitMEMLOCK = "infinity";
      };
    };

    # Firewall
    networking.firewall.allowedTCPPorts = mkIf cfg.enable [ cfg.port ];

    # Health check timer (optional)
    systemd.services.tabbyapi-healthcheck = {
      description = "TabbyAPI Health Check";
      after = [ "tabbyapi.service" ];
      serviceConfig = {
        Type = "oneshot";
        ExecStart = pkgs.writeShellScript "tabbyapi-healthcheck" ''
          response=$(${pkgs.curl}/bin/curl -sf http://localhost:${toString cfg.port}/health || echo "failed")
          if [ "$response" = "failed" ]; then
            echo "TabbyAPI health check failed"
            exit 1
          fi
          echo "TabbyAPI healthy"
        '';
      };
    };

    systemd.timers.tabbyapi-healthcheck = {
      description = "TabbyAPI Health Check Timer";
      wantedBy = [ "timers.target" ];
      timerConfig = {
        OnBootSec = "5min";
        OnUnitActiveSec = "5min";
      };
    };
  };
}
